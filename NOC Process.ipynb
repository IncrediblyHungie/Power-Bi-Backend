{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd180c46-606d-49d2-a7c1-de0586177666",
   "metadata": {},
   "source": [
    "This code performs the following steps:\n",
    "\n",
    "1. **Import Libraries**: It imports the necessary libraries: `os` for interacting with the operating system, `pandas` for data manipulation, and `numpy` for numerical operations.\n",
    "\n",
    "2. **Define Directories**: It specifies two directories containing CSV files: `'C:\\\\Users\\\\pskotte\\\\Desktop\\\\New folder'` and `'C:\\\\Users\\\\pskotte\\\\Desktop\\\\ILMS'`.\n",
    "\n",
    "3. **Determine Source Function**: It defines a function `determine_source(filepath)` that determines the source of the file based on its directory. If the file is in the 'New folder' directory, it returns 'DM'. If the file is in the 'ILMS' directory, it returns 'ILMS'. Otherwise, it returns 'Unknown'.\n",
    "\n",
    "4. **Read and Concatenate CSV Files**: It iterates through the specified directories, reads all CSV files, and appends them to a list `df_list`. Each DataFrame is augmented with a 'Source' column indicating its origin.\n",
    "\n",
    "5. **Concatenate DataFrames**: It concatenates all DataFrames in `df_list` into a single DataFrame `combined_df`.\n",
    "\n",
    "6. **Filter Non-Blank Rows**: It defines a list of columns to check for non-blank values. It filters `combined_df` to keep only rows where at least one of these columns has a non-blank value. It further filters each column to remove rows where the column value is blank or consists only of whitespace.\n",
    "\n",
    "7. **Convert Column Type**: It converts the 'Invalid NOC Info 1' column to string type to avoid any potential `TypeError`.\n",
    "\n",
    "8. **Sort DataFrame**: It sorts the filtered DataFrame `filtered_df` by the 'Invalid NOC Info 1' column and stores the result in `sorted_df`.\n",
    "\n",
    "9. **Display DataFrame**: Finally, it displays the sorted DataFrame `sorted_df`.\n",
    "\n",
    "This code effectively reads multiple CSV files from specified directories, filters out rows with blank values in certain columns, and sorts the resulting DataFrame by a specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd6b5e-e13e-41b1-9f66-d45b347edeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Directories containing the CSV files\n",
    "directories = [\n",
    "    'C:\\\\Users\\\\pskotte\\\\Desktop\\\\New folder',\n",
    "    'C:\\\\Users\\\\pskotte\\\\Desktop\\\\ILMS'\n",
    "]\n",
    "\n",
    "# Function to determine source\n",
    "def determine_source(filepath):\n",
    "    if 'New folder' in filepath:\n",
    "        return 'DM'\n",
    "    elif 'ILMS' in filepath:\n",
    "        return 'ILMS'\n",
    "    return 'Unknown'\n",
    "\n",
    "# Read and concatenate all CSV files in the directories\n",
    "df_list = []\n",
    "for directory in directories:\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['Source'] = determine_source(file_path)\n",
    "            df_list.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Columns to check for non-blank values\n",
    "columns_to_check = [\n",
    "    'Invalid NOC Info 1', 'Valid NOC Info 1',\n",
    "    'Invalid NOC Info 2', 'Valid NOC Info 2',\n",
    "    'Invalid NOC Info 3', 'Valid NOC Info 3'\n",
    "]\n",
    "\n",
    "# Filter the dataframe to only keep rows where any of the columns have non-blank values\n",
    "filtered_df = combined_df.dropna(subset=columns_to_check, how='all')\n",
    "\n",
    "for column in columns_to_check:\n",
    "    filtered_df = filtered_df[filtered_df[column].astype(str).str.strip() != '']\n",
    "\n",
    "# Convert 'Invalid NOC Info 1' column to string type to avoid TypeError\n",
    "filtered_df['Invalid NOC Info 1'] = filtered_df['Invalid NOC Info 1'].astype(str)\n",
    "\n",
    "# Sort the filtered dataframe by 'Invalid NOC Info 1' column\n",
    "sorted_df = filtered_df.sort_values(by='Invalid NOC Info 1')\n",
    "\n",
    "# Display the sorted dataframe\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c688c95-ff74-4db3-beb8-74baa705a2bd",
   "metadata": {},
   "source": [
    "This code performs the following steps:\n",
    "\n",
    "1. **Import Libraries**: It imports the necessary libraries: `pandas` for data manipulation, `pyodbc` for connecting to the SQL Server, and `re` for regular expression operations.\n",
    "\n",
    "2. **SQL Server Connection**: It establishes a connection to a SQL Server database using the provided connection string (`conn_str`). The connection is stored in the `conn` variable, and a cursor object is created for executing SQL queries.\n",
    "\n",
    "3. **Extract Receiver IDs**: It assumes that `sorted_df` is a DataFrame containing a column named 'Receiver ID'. It extracts the unique values from this column and stores them in the `receiver_ids` array.\n",
    "\n",
    "4. **Clean Receiver IDs**: It removes specific substrings ('SP', 'LAL', and '-') from each Receiver ID and strips any leading or trailing whitespace. The cleaned Receiver IDs are stored in the `cleaned_receiver_ids` array.\n",
    "\n",
    "5. **Separate Numerical and Non-Numerical IDs**: It separates the cleaned Receiver IDs into numerical and non-numerical IDs using regular expressions. Numerical IDs are stored in the `numerical_ids` array, and non-numerical IDs are stored in the `non_numerical_ids` array.\n",
    "\n",
    "6. **Print Count of Non-Numerical IDs**: It prints the count of non-numerical Receiver IDs.\n",
    "\n",
    "7. **Format Numerical IDs for SQL Query**: It formats the numerical Receiver IDs into a comma-separated string (`formatted_ids`) for use in an SQL query.\n",
    "\n",
    "8. **SQL Query Execution**: It defines an SQL query template (`sql_template`) to retrieve the MCM Account Number and Receiver ID from the database. The query is executed using the formatted numerical Receiver IDs, and the result is stored in the `result_df` DataFrame.\n",
    "\n",
    "9. **Update DataFrame**: It merges the `result_df` DataFrame with `sorted_df` based on the 'Receiver ID' column. The 'Receiver ID' column is dropped after merging, and the 'MCM Account Number' column is updated with the values from the `result_df`. The temporary 'MCM_Account_Number' column is then removed.\n",
    "\n",
    "10. **Count NaN or Blank Values**: It counts the number of rows in the 'MCM Account Number' column that have NaN or blank values and prints the count.\n",
    "\n",
    "11. **Close Connection**: It closes the cursor and the database connection.\n",
    "\n",
    "12. **Display DataFrame**: It displays the first few rows of the updated `sorted_df` DataFrame.\n",
    "\n",
    "This code effectively cleans and processes Receiver IDs, retrieves corresponding MCM Account Numbers from a SQL Server database, updates the DataFrame, and counts the number of rows with missing or blank MCM Account Numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054f649-2756-49fb-bf68-25e2c1b865e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import re\n",
    "\n",
    "# SQL Server Connection String\n",
    "conn_str = (\n",
    "    r'Driver={SQL Server};'\n",
    "    r'Server=rpt_ap_prd.internal.mcmcg.com;'\n",
    "    r'Database=crs5_oltp;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Assuming 'sorted_df' is your DataFrame with 'Receiver ID'\n",
    "receiver_ids = sorted_df['Receiver ID'].unique()\n",
    "\n",
    "# Remove 'SP', 'LAL', and '-' from Receiver IDs and strip whitespaces\n",
    "cleaned_receiver_ids = [re.sub(r'(SP|LAL|-)', '', str(id)).strip() for id in receiver_ids]\n",
    "\n",
    "# Separate numerical and non-numerical Receiver IDs\n",
    "numerical_ids = [id for id in cleaned_receiver_ids if re.match(r'^\\d+$', str(id))]\n",
    "non_numerical_ids = [id for id in cleaned_receiver_ids if not re.match(r'^\\d+$', str(id))]\n",
    "\n",
    "# Print the count of non-numerical Receiver IDs\n",
    "print(f\"Count of non-numerical Receiver IDs: {len(non_numerical_ids)}\")\n",
    "\n",
    "# Directly format the numerical receiver IDs for the SQL query\n",
    "formatted_ids = ','.join([str(id) for id in numerical_ids])\n",
    "\n",
    "sql_template = ''' \n",
    "SELECT ca.cnsmr_accnt_idntfr_agncy_id as MCM_Account_Number, capj.cnsmr_pymnt_jrnl_id as Receiver_ID \n",
    "from cnsmr_accnt ca\n",
    "inner join cnsmr_accnt_pymnt_jrnl capj on ca.cnsmr_accnt_id  = capj.cnsmr_accnt_id\n",
    "WHERE cnsmr_pymnt_jrnl_id in ({})\n",
    "'''\n",
    "\n",
    "query = sql_template.format(formatted_ids)\n",
    "result_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Update the 'MCM Account Number' in 'sorted_df' based on 'Receiver ID'\n",
    "sorted_df = pd.merge(sorted_df, result_df[['Receiver_ID', 'MCM_Account_Number']], left_on='Receiver ID', right_on='Receiver_ID', how='left')\n",
    "sorted_df.drop(columns=['Receiver_ID'], inplace=True)  # Remove the 'Receiver_ID' column after merging\n",
    "sorted_df['MCM Account Number'] = sorted_df['MCM_Account_Number']\n",
    "sorted_df.drop(columns=['MCM_Account_Number'], inplace=True)  # Remove the temporary 'MCM_Account_Number' column\n",
    "\n",
    "# Count the number of columns with NaN or blank values for 'MCM Account Number'\n",
    "nan_or_blank_count = sorted_df['MCM Account Number'].isna().sum() + (sorted_df['MCM Account Number'].astype(str).str.strip() == '').sum()\n",
    "print(f\"Number of columns with NaN or blank 'MCM Account Number': {nan_or_blank_count}\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "cursor.close()\n",
    "conn.close()\n",
    "sorted_df.head()\n",
    "\n",
    "# Assuming 'sorted_df' is your DataFrame with the 'Receiver ID' column\n",
    "# Remove alphabetical characters and '-' from 'Receiver ID'\n",
    "sorted_df['Receiver ID'] = sorted_df['Receiver ID'].apply(lambda x: re.sub(r'[a-zA-Z-]', '', str(x)).strip())\n",
    "\n",
    "# Display the updated DataFrame\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e95ee-3163-4aed-99c4-eb4db46f47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a CSV file\n",
    "sorted_df.to_csv(r'C:\\Users\\pskotte\\Desktop\\sorted_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9a61d-1ee4-4979-a791-1d9012a3bdc6",
   "metadata": {},
   "source": [
    "ENSURE THAT ALL OF THE MCM ACCOUNT NUMBERS ARE PRESENT IN THE DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880dea6c-1747-49fc-b297-83eb12e0d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sorted_df = pd.read_csv(r'C:\\Users\\pskotte\\Desktop\\sorted_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd3a50-3b21-4072-a027-ed7d909af98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the Report Date column is in datetime format\n",
    "sorted_df['Report Date'] = pd.to_datetime(sorted_df['Report Date'], errors='coerce')\n",
    "\n",
    "# Group by 'MCM Account Number' and get the earliest Report Date for each group\n",
    "early_report_dates = sorted_df.groupby('MCM Account Number')['Report Date'].min().reset_index()\n",
    "early_report_dates.rename(columns={'Report Date': 'Earliest Report Date'}, inplace=True)\n",
    "\n",
    "# Merge the earliest report dates back to the original dataframe\n",
    "sorted_df = pd.merge(sorted_df, early_report_dates, on='MCM Account Number', how='left')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e121a6-3673-4db9-9111-612866a0a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import sqlalchemy as sa\n",
    "import re\n",
    "\n",
    "# Azure Synapse Connection String\n",
    "conn_str = (\n",
    "    r'Driver={ODBC Driver 17 for SQL Server};'\n",
    "    r'Server=tcp:azwsynt00.sql.azuresynapse.net,1433;'\n",
    "    r'Database=AZWSYNT00;'\n",
    "    r'Authentication=ActiveDirectoryIntegrated;'\n",
    ")\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = sa.create_engine(f'mssql+pyodbc:///?odbc_connect={conn_str}')\n",
    "\n",
    "# Assuming 'sorted_df' is your DataFrame with 'MCM Account Number'\n",
    "sorted_df['MCM Account Number'] = sorted_df['MCM Account Number'].astype(str).apply(lambda x: x.split('.')[0])\n",
    "\n",
    "# Drop rows where 'MCM Account Number' is NaN or 'nan'\n",
    "sorted_df = sorted_df[sorted_df['MCM Account Number'].notna() & (sorted_df['MCM Account Number'] != 'nan')]\n",
    "\n",
    "account_numbers = sorted_df['MCM Account Number'].unique()\n",
    "\n",
    "# Format account numbers for SQL query\n",
    "formatted_account_numbers = ','.join([f\"'{str(num)}'\" for num in account_numbers])\n",
    "\n",
    "sql_query = f'''\n",
    "SELECT\n",
    "cpj.ConsumerPaymentJournalID,\n",
    "cpj.BucketTransactionTypeCode, -- 2 PAYMENT 4 NSF 9 REVERSAL\n",
    " da.DimAccountKey, -- the one to match to dw.Fact_Collection.DimAccountKey\n",
    " da.AccountID, -- that one that matches capj.ConsumerAccountID\n",
    " da.AccountNumber AS 'MCM Account Number 1', -- mcm account number the one we show our consumers and vendors\n",
    " capj.ConsumerAccountPaymentAmount,\n",
    " capj.ConsumerAccountPaymentBalanceAmount,\n",
    " capj.ConsumerAccountPaymentIsNSFFlag,\n",
    " FORMAT(capj.ConsumerAccountPaymentPostedDate, 'yyyy-MM-dd') as ConsumerAccountPaymentPostedDate\n",
    "FROM ref.DM_Consumer_Payment_Journal cpj\n",
    "INNER JOIN ref.DM_Consumer_Account_Payment_Journal capj\n",
    "ON (cpj.ConsumerPaymentJournalID = capj.ConsumerPaymentJournalID)\n",
    "INNER JOIN dw.Dim_Account da\n",
    "ON (capj.ConsumerAccountID = da.AccountID)\n",
    "WHERE da.AccountNumber IN ({formatted_account_numbers})\n",
    "ORDER BY cpj.ConsumerPaymentJournalID\n",
    "'''\n",
    "\n",
    "# Execute the query using SQLAlchemy engine\n",
    "result_df = pd.read_sql_query(sql_query, engine)\n",
    "\n",
    "# Convert the column in result_df to string to match sorted_df\n",
    "result_df['MCM Account Number 1'] = result_df['MCM Account Number 1'].astype(str)\n",
    "\n",
    "# Merge only Earliest Report Date from sorted_df with result_df based on 'MCM Account Number' and 'MCM Account Number 1'\n",
    "df_merged = pd.merge(sorted_df[['MCM Account Number', 'Earliest Report Date']], result_df, left_on='MCM Account Number', right_on='MCM Account Number 1', how='left')\n",
    "\n",
    "# Count the number of columns with NaN or blank values\n",
    "nan_count = df_merged.isna().sum().sum()\n",
    "blank_count = df_merged.apply(lambda x: x.astype(str).str.strip().eq('').sum()).sum()\n",
    "nan_or_blank_count = nan_count + blank_count\n",
    "print(f\"Number of columns with NaN or blank values: {nan_or_blank_count}\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f86135d-4b36-4822-99be-c4c508ee59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Convert 'Earliest Report Date' and 'ConsumerAccountPaymentPostedDate' to datetime\n",
    "df_merged['Earliest Report Date'] = pd.to_datetime(df_merged['Earliest Report Date'], errors='coerce')\n",
    "df_merged['ConsumerAccountPaymentPostedDate'] = pd.to_datetime(df_merged['ConsumerAccountPaymentPostedDate'], errors='coerce')\n",
    "\n",
    "# Filter the DataFrame to include dates after 'Earliest Report Date' and newer than 11/01/2023\n",
    "filtered_df = df_merged[(df_merged['ConsumerAccountPaymentPostedDate'] >= df_merged['Earliest Report Date']) & (df_merged['ConsumerAccountPaymentPostedDate'] >= pd.to_datetime('2023-11-01'))]\n",
    "\n",
    "# Add a column that counts the occurrences of each 'ConsumerPaymentJournalID'\n",
    "filtered_df['ConsumerPaymentJournalID_Count'] = filtered_df.groupby('ConsumerPaymentJournalID')['ConsumerPaymentJournalID'].transform('count')\n",
    "\n",
    "# Create a hash value for each row to identify duplicates\n",
    "def hash_row(row):\n",
    "    row_string = ''.join(row.values.astype(str))\n",
    "    return hashlib.md5(row_string.encode()).hexdigest()\n",
    "\n",
    "# Apply the hash function to each row and create a new column 'hash_value'\n",
    "filtered_df['hash_value'] = filtered_df.apply(hash_row, axis=1)\n",
    "\n",
    "# Add a column that counts the occurrences of each 'hash_value'\n",
    "filtered_df['hash_value_count'] = filtered_df.groupby('hash_value')['hash_value'].transform('count')\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406af7da-b873-4e00-b7cb-524ef4ff4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4645c46-d2c4-40a1-ae13-404117c7b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame to a CSV file\n",
    "filtered_df.to_csv(r'C:\\Users\\pskotte\\Desktop\\filtered_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7ddb7-2154-4a1d-b28d-5a316cd0e028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
