{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac214713-7a1a-4f79-96c8-6b06638f44e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILMS Card DataFrame:\n",
      "         Date Payment Method  Total Amount  Total Count\n",
      "0  2023-09-01           Card     226028.26         1994\n",
      "3  2023-09-02           Card      86299.20          643\n",
      "4  2023-09-03           Card      66199.06          873\n",
      "6  2023-09-04           Card      73891.70          789\n",
      "8  2023-09-05           Card     189253.90         1090\n",
      "ILMS ACH DataFrame:\n",
      "           Date Payment Method  Total Amount  Total Count\n",
      "546  2024-05-31            ACH    1434128.18         9354\n",
      "548  2024-06-01            ACH     273265.50         2574\n",
      "550  2024-06-02            ACH      93146.36          921\n",
      "553  2024-06-03            ACH     274006.18         2053\n",
      "555  2024-06-04            ACH     111077.70         1236\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define the connection string\n",
    "conn_str = (\n",
    "    'Driver={ODBC Driver 17 for SQL Server};'\n",
    "    'Server=azwsynt00.sql.azuresynapse.net;'\n",
    "    'Database=AZWSYNT00;'\n",
    "    'Authentication=ActiveDirectoryIntegrated;'\n",
    ")\n",
    "\n",
    "# Use SQLAlchemy to create the engine\n",
    "engine = create_engine(f'mssql+pyodbc:///?odbc_connect={conn_str}')\n",
    "\n",
    "# Define the SQL query\n",
    "query = '''\n",
    "WITH latest_PPA AS (\n",
    "    SELECT\n",
    "        dad.ACCOUNTNUMBER,\n",
    "        DPP.writtendate,\n",
    "        paymentplankey,\n",
    "        ROW_NUMBER() OVER (PARTITION BY dad.accountnumber ORDER BY dpp.writtendate DESC) AS rows\n",
    "    FROM dw.ILMS_DIM_ACCOUNT_DETAIL dad\n",
    "    LEFT JOIN dw.ILMS_DIM_PAYMENT_PLAN dpp\n",
    "        ON dpp.ACCOUNTDETAILKEY = dad.accountdetailkey\n",
    "),\n",
    "latest_PPA1 AS (\n",
    "    SELECT *\n",
    "    FROM latest_PPA\n",
    "    WHERE rows = 1\n",
    ")\n",
    "SELECT\n",
    "    CONVERT(VARCHAR, dppd.duedate, 23) AS duedate,  -- Converting to YYYY-MM-DD format\n",
    "    CASE \n",
    "        WHEN dppd.paymentmethod IN ('Debit Card', 'Credit Card') THEN 'Card'\n",
    "        ELSE dppd.paymentmethod\n",
    "    END AS paymentmethod,\n",
    "    SUM(dppd.paymentamount) AS total_payment_amount,\n",
    "    COUNT(dppd.paymentamount) AS item_count  -- adding count of items per day\n",
    "FROM latest_PPA1 dpp\n",
    "INNER JOIN dw.ILMS_DIM_PAYMENT_PLAN_DETAIL dppd\n",
    "    ON dppd.PAYMENTPLANKEY = dpp.PAYMENTPLANKEY\n",
    "WHERE dppd.duedate BETWEEN '2023-09-01' AND CAST(GETDATE() AS DATE)\n",
    "  AND (CASE \n",
    "        WHEN dppd.paymentmethod IN ('Debit Card', 'Credit Card') THEN 'Card'\n",
    "        ELSE dppd.paymentmethod\n",
    "     END) IN ('Card', 'ACH')\n",
    "GROUP BY CONVERT(VARCHAR, dppd.duedate, 23), CASE \n",
    "        WHEN dppd.paymentmethod IN ('Debit Card', 'Credit Card') THEN 'Card'\n",
    "        ELSE dppd.paymentmethod\n",
    "     END\n",
    "ORDER BY duedate;\n",
    "'''\n",
    "\n",
    "# Execute the query and fetch the results into a DataFrame\n",
    "results_df = pd.read_sql(query, engine)\n",
    "\n",
    "# Rename the columns\n",
    "results_df.columns = ['Date', 'Payment Method', 'Total Amount', 'Total Count']\n",
    "\n",
    "# Split the result into two DataFrames based on 'paymentmethod'\n",
    "ilms_card = results_df[results_df['Payment Method'] == 'Card']\n",
    "ilms_ach = results_df[results_df['Payment Method'] == 'ACH']\n",
    "\n",
    "# Display the DataFrames for verification\n",
    "print(\"ILMS Card DataFrame:\")\n",
    "print(ilms_card.head())\n",
    "\n",
    "print(\"ILMS ACH DataFrame:\")\n",
    "print(ilms_ach.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a021201a-4db1-483b-b7e4-f846ad521b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:55:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:55:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "13:55:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:55:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILMS Card Predictions DataFrame:\n",
      "        Date  Prophet Prediction  Average of the Last 4 Similar Weekdays  \\\n",
      "0 2024-06-04         1068.552635                                 1096.75   \n",
      "\n",
      "   Actual  Closer Prediction  Percentage Difference  \n",
      "0    1112            1096.75               0.013714  \n",
      "ILMS ACH Predictions DataFrame:\n",
      "        Date  Prophet Prediction  Average of the Last 4 Similar Weekdays  \\\n",
      "0 2024-06-04         1067.252095                                  1410.0   \n",
      "\n",
      "   Actual  Closer Prediction  Percentage Difference  \n",
      "0    1236        1067.252095               0.136527  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "\n",
    "# Split the result into two DataFrames based on 'paymentmethod'\n",
    "ilms_card = results_df[results_df['Payment Method'] == 'Card'].copy()\n",
    "ilms_ach = results_df[results_df['Payment Method'] == 'ACH'].copy()\n",
    "\n",
    "# Function for predictive modeling\n",
    "\n",
    "def predictive_modeling(df):\n",
    "    # Convert the 'Date' column to datetime in the correct format\n",
    "    df.loc[:, 'Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')  # Fix for SettingWithCopyWarning\n",
    "    \n",
    "    # Ensure the index is set correctly after date conversion\n",
    "    df.set_index('Date', inplace=True)\n",
    "    \n",
    "    data = df['Total Count']\n",
    "\n",
    "    # Prophet model\n",
    "    df_prophet = df.reset_index().rename(columns={'Date': 'ds', 'Total Count': 'y'})\n",
    "    model = Prophet(seasonality_mode='multiplicative', seasonality_prior_scale=1.5)\n",
    "    model.add_seasonality(name='weekly', period=7, fourier_order=5)\n",
    "    model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "    model.add_seasonality(name='yearly', period=365.25, fourier_order=10)\n",
    "    model.fit(df_prophet)\n",
    "    future = model.make_future_dataframe(periods=1, freq='D')\n",
    "    forecast = model.predict(future)\n",
    "    prophet_prediction = forecast.iloc[-2]['yhat']  # Changed from -1 to -2 to make the prediction on yesterday\n",
    "\n",
    "    prediction_date = df.index.max()  # Changed from df.index.max() + pd.Timedelta(days=1)\n",
    "\n",
    "    # Calculate the average of the last 4 similar weekdays\n",
    "    weekdays_data = df[df.index.weekday == prediction_date.weekday()]['Total Count']\n",
    "    last_4_similar_weekdays = weekdays_data.tail(4).mean() if len(weekdays_data) > 0 else None\n",
    "\n",
    "    return prediction_date, prophet_prediction, last_4_similar_weekdays\n",
    "\n",
    "# Run predictive modeling for both dataframes\n",
    "pred_date_card, prophet_card, avg_weekdays_card = predictive_modeling(ilms_card)\n",
    "pred_date_ach, prophet_ach, avg_weekdays_ach = predictive_modeling(ilms_ach)\n",
    "\n",
    "# Reset the index to reintroduce 'Date' column for comparison\n",
    "ilms_card.reset_index(inplace=True)\n",
    "ilms_ach.reset_index(inplace=True)\n",
    "\n",
    "# Fetch actual values for the prediction dates\n",
    "actual_card = ilms_card[ilms_card['Date'] == pred_date_card]['Total Count']  # Changed from pred_date_card - pd.Timedelta(days=1)\n",
    "actual_ach = ilms_ach[ilms_ach['Date'] == pred_date_ach]['Total Count']  # Changed from pred_date_ach - pd.Timedelta(days=1)\n",
    "\n",
    "actual_card = actual_card.values[0] if not actual_card.empty else None\n",
    "actual_ach = actual_ach.values[0] if not actual_ach.empty else None\n",
    "\n",
    "# Create DataFrames for predictions and actual values\n",
    "card_predictions = pd.DataFrame({\n",
    "    'Date': [pred_date_card],\n",
    "    'Prophet Prediction': [prophet_card],\n",
    "    'Average of the Last 4 Similar Weekdays': [avg_weekdays_card],\n",
    "    'Actual': [actual_card],\n",
    "    'Closer Prediction': [prophet_card if actual_card is not None and abs(prophet_card - actual_card) < abs(avg_weekdays_card - actual_card) else avg_weekdays_card]\n",
    "})\n",
    "card_predictions['Percentage Difference'] = (abs(card_predictions['Actual'] - card_predictions['Closer Prediction']) / card_predictions['Actual'])\n",
    "\n",
    "ach_predictions = pd.DataFrame({\n",
    "    'Date': [pred_date_ach],\n",
    "    'Prophet Prediction': [prophet_ach],\n",
    "    'Average of the Last 4 Similar Weekdays': [avg_weekdays_ach],\n",
    "    'Actual': [actual_ach],\n",
    "    'Closer Prediction': [prophet_ach if actual_ach is not None and abs(prophet_ach - actual_ach) < abs(avg_weekdays_ach - actual_ach) else avg_weekdays_ach]\n",
    "})\n",
    "ach_predictions['Percentage Difference'] = (abs(ach_predictions['Actual'] - ach_predictions['Closer Prediction']) / ach_predictions['Actual'])\n",
    "\n",
    "# Display the DataFrames for verification\n",
    "print(\"ILMS Card Predictions DataFrame:\")\n",
    "print(card_predictions.head())\n",
    "\n",
    "print(\"ILMS ACH Predictions DataFrame:\")\n",
    "print(ach_predictions.head())\n",
    "\n",
    "# Export DataFrames to CSV\n",
    "card_predictions.to_csv(r'C:\\Users\\pskotte\\Desktop\\Power Bi Data\\ILMSCardPredictions.csv', index=False)\n",
    "ach_predictions.to_csv(r'C:\\Users\\pskotte\\Desktop\\Power Bi Data\\ILMSACHPredictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af404e31-fdaf-4388-95b1-7e7f6c20ca9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
